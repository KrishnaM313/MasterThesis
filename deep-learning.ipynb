{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('masterthesis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a6ef8c17562cbfe29ba74c402109b46d584d06497c1b6ed2b0308a396394d487"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Download pretrained model \n",
    "https://ai2-s2-research.s3-us-west-2.amazonaws.com/longformer/longformer-large-4096.tar.gz\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - cudatoolkit=10.0\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "Collecting git+https://github.com/allenai/longformer.git\n",
      "  Cloning https://github.com/allenai/longformer.git to /private/var/folders/r3/zbc0j5755cd424h_f2g7b53h0000gr/T/pip-req-build-ipk36ze8\n",
      "  Running command git clone -q https://github.com/allenai/longformer.git /private/var/folders/r3/zbc0j5755cd424h_f2g7b53h0000gr/T/pip-req-build-ipk36ze8\n",
      "Collecting transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers\n",
      "  Cloning http://github.com/ibeltagy/transformers.git (to revision longformer_encoder_decoder) to /private/var/folders/r3/zbc0j5755cd424h_f2g7b53h0000gr/T/pip-install-zif3jdmg/transformers_e00846052b4f4fcdbdb7b5deb6b09308\n",
      "  Running command git clone -q http://github.com/ibeltagy/transformers.git /private/var/folders/r3/zbc0j5755cd424h_f2g7b53h0000gr/T/pip-install-zif3jdmg/transformers_e00846052b4f4fcdbdb7b5deb6b09308\n",
      "  Running command git checkout -b longformer_encoder_decoder --track origin/longformer_encoder_decoder\n",
      "  Zu neuem Branch 'longformer_encoder_decoder' gewechselt\n",
      "  Branch 'longformer_encoder_decoder' folgt nun Remote-Branch 'longformer_encoder_decoder' von 'origin'.\n",
      "Collecting pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning\n",
      "  Cloning http://github.com/ibeltagy/pytorch-lightning.git (to revision v0.8.5_fixes) to /private/var/folders/r3/zbc0j5755cd424h_f2g7b53h0000gr/T/pip-install-zif3jdmg/pytorch-lightning_de58e139becc4e57a7cb10ee43881e9d\n",
      "  Running command git clone -q http://github.com/ibeltagy/pytorch-lightning.git /private/var/folders/r3/zbc0j5755cd424h_f2g7b53h0000gr/T/pip-install-zif3jdmg/pytorch-lightning_de58e139becc4e57a7cb10ee43881e9d\n",
      "  Running command git checkout -b v0.8.5_fixes --track origin/v0.8.5_fixes\n",
      "  Zu neuem Branch 'v0.8.5_fixes' gewechselt\n",
      "  Branch 'v0.8.5_fixes' folgt nun Remote-Branch 'v0.8.5_fixes' von 'origin'.\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch==1.6.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from longformer==0.1) (1.6.0)\n",
      "Requirement already satisfied: tensorboardX in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from longformer==0.1) (2.1)\n",
      "Requirement already satisfied: test-tube==0.7.5 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from longformer==0.1) (0.7.5)\n",
      "Requirement already satisfied: nlp in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from longformer==0.1) (0.4.0)\n",
      "Requirement already satisfied: rouge_score in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from longformer==0.1) (0.0.4)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (1.20.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (4.59.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (0.18.2)\n",
      "Requirement already satisfied: tensorboard>=1.14 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (2.4.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.8.1rc2)\n",
      "Requirement already satisfied: packaging in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (20.9)\n",
      "Requirement already satisfied: filelock in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (3.0.12)\n",
      "Requirement already satisfied: requests in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (2020.11.13)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.1.95)\n",
      "Requirement already satisfied: sacremoses in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.0.43)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from test-tube==0.7.5->longformer==0.1) (2.9.0)\n",
      "Requirement already satisfied: pandas>=0.20.3 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from test-tube==0.7.5->longformer==0.1) (1.2.3)\n",
      "Requirement already satisfied: pillow in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from imageio>=2.3.0->test-tube==0.7.5->longformer==0.1) (8.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (1.15.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (3.15.5)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (1.27.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (0.12.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (1.36.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (0.4.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from requests->transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from requests->transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from requests->transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from requests->transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (3.1.0)\n",
      "Requirement already satisfied: dill in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from nlp->longformer==0.1) (0.3.3)\n",
      "Requirement already satisfied: pyarrow>=0.16.0 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from nlp->longformer==0.1) (3.0.0)\n",
      "Requirement already satisfied: xxhash in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from nlp->longformer==0.1) (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from packaging->transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (2.4.7)\n",
      "Requirement already satisfied: nltk in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from rouge_score->longformer==0.1) (3.5)\n",
      "Requirement already satisfied: click in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from nltk->rouge_score->longformer==0.1) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/michael/bin/anaconda3/envs/masterthesis/lib/python3.8/site-packages (from nltk->rouge_score->longformer==0.1) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "#!conda create --name longformer python=3.7\n",
    "#!conda activate longformer\n",
    "!conda install cudatoolkit=10.0\n",
    "!pip install git+https://github.com/allenai/longformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 899k/899k [00:00<00:00, 2.42MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 979kB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from longformer.longformer import Longformer, LongformerConfig\n",
    "from longformer.sliding_chunks import pad_to_window_size\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "config = LongformerConfig.from_pretrained('longformer-large-4096/') \n",
    "# choose the attention mode 'n2', 'tvm' or 'sliding_chunks'\n",
    "# 'n2': for regular n2 attantion\n",
    "# 'tvm': a custom CUDA kernel implementation of our sliding window attention\n",
    "# 'sliding_chunks': a PyTorch implementation of our sliding window attention\n",
    "config.attention_mode = 'sliding_chunks'\n",
    "\n",
    "model = Longformer.from_pretrained('longformer-large-4096/', config=config)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer.model_max_length = model.config.max_position_embeddings\n",
    "\n",
    "SAMPLE_TEXT = ' '.join(['Hello world! '] * 1000)  # long input document\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(SAMPLE_TEXT)).unsqueeze(0)  # batch of size 1\n",
    "\n",
    "# TVM code doesn't work on CPU. Uncomment this if `config.attention_mode = 'tvm'`\n",
    "# model = model.cuda(); input_ids = input_ids.cuda()\n",
    "\n",
    "# Attention mask values -- 0: no attention, 1: local attention, 2: global attention\n",
    "attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device) # initialize to local attention\n",
    "attention_mask[:, [1, 4, 21,]] =  2  # Set global attention based on the task. For example,\n",
    "                                     # classification: the <s> token\n",
    "                                     # QA: question tokens\n",
    "\n",
    "# padding seqlen to the nearest multiple of 512. Needed for the 'sliding_chunks' attention\n",
    "input_ids, attention_mask = pad_to_window_size(\n",
    "        input_ids, attention_mask, config.attention_window[0], tokenizer.pad_token_id)\n",
    "\n",
    "output = model(input_ids, attention_mask=attention_mask)[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-0.0414,  0.0574, -0.5770,  ..., -0.2942, -0.2785,  0.1179],\n",
       "         [ 0.2158,  0.3126, -0.9947,  ..., -0.8295, -0.2143,  0.0195],\n",
       "         [ 0.3286,  0.4128, -0.2817,  ...,  0.4203, -0.5912,  0.6113],\n",
       "         ...,\n",
       "         [-0.1238,  0.3869,  0.2201,  ..., -0.6698,  0.5555,  0.0536],\n",
       "         [-0.1238,  0.3869,  0.2201,  ..., -0.6698,  0.5555,  0.0536],\n",
       "         [-0.1238,  0.3869,  0.2201,  ..., -0.6698,  0.5555,  0.0536]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}